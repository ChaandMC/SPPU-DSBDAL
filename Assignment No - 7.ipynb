{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.probability import FreqDist\n",
        "from nltk import pos_tag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2uASNQP4YGu",
        "outputId": "c4f3d8d2-dac0-4b4c-c376-c0f41ce03c7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFLoIaOS4yrh",
        "outputId": "2e939356-3053-47c0-be92-b09ff98b01ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document = \"\"\"\n",
        "Caltech astrophysicist finds proof of alien life.\n",
        "Amy you are neuroscientist and you know the latest research into  deja-vu is nothing but the frontal regions of the brain attempting to correct an inaccurate memory.\n",
        "Sheldon Cooper is a theoretical physicist at caltech university and is running up for nobel prize for his theory of asymmetry and symmetry in universe.\n",
        "Sheldon does not think that dr. leonard should demand to be in charge of a plasma project.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "qmea6Dub41nV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(document)\n",
        "for token in tokens:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KSjFZFk6ERt",
        "outputId": "9982fcc7-c177-4be7-8ca6-40329439ce50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caltech\n",
            "astrophysicist\n",
            "finds\n",
            "proof\n",
            "of\n",
            "alien\n",
            "life\n",
            ".\n",
            "Amy\n",
            "you\n",
            "are\n",
            "neuroscientist\n",
            "and\n",
            "you\n",
            "know\n",
            "the\n",
            "latest\n",
            "research\n",
            "into\n",
            "deja-vu\n",
            "is\n",
            "nothing\n",
            "but\n",
            "the\n",
            "frontal\n",
            "regions\n",
            "of\n",
            "the\n",
            "brain\n",
            "attempting\n",
            "to\n",
            "correct\n",
            "an\n",
            "inaccurate\n",
            "memory\n",
            ".\n",
            "Sheldon\n",
            "Cooper\n",
            "is\n",
            "a\n",
            "theoretical\n",
            "physicist\n",
            "at\n",
            "caltech\n",
            "university\n",
            "and\n",
            "is\n",
            "running\n",
            "up\n",
            "for\n",
            "nobel\n",
            "prize\n",
            "for\n",
            "his\n",
            "theory\n",
            "of\n",
            "asymmetry\n",
            "and\n",
            "symmetry\n",
            "in\n",
            "universe\n",
            ".\n",
            "Sheldon\n",
            "does\n",
            "not\n",
            "think\n",
            "that\n",
            "dr.\n",
            "leonard\n",
            "should\n",
            "demand\n",
            "to\n",
            "be\n",
            "in\n",
            "charge\n",
            "of\n",
            "a\n",
            "plasma\n",
            "project\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_tags = pos_tag(tokens)\n",
        "for tag in pos_tags:\n",
        "  print(tag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4dS7ae96poA",
        "outputId": "c0c482a6-15d2-4256-b910-6df54062ff5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Caltech', 'NNP')\n",
            "('astrophysicist', 'NN')\n",
            "('finds', 'VBZ')\n",
            "('proof', 'NN')\n",
            "('of', 'IN')\n",
            "('alien', 'JJ')\n",
            "('life', 'NN')\n",
            "('.', '.')\n",
            "('Amy', 'NNP')\n",
            "('you', 'PRP')\n",
            "('are', 'VBP')\n",
            "('neuroscientist', 'JJ')\n",
            "('and', 'CC')\n",
            "('you', 'PRP')\n",
            "('know', 'VBP')\n",
            "('the', 'DT')\n",
            "('latest', 'JJS')\n",
            "('research', 'NN')\n",
            "('into', 'IN')\n",
            "('deja-vu', 'NN')\n",
            "('is', 'VBZ')\n",
            "('nothing', 'NN')\n",
            "('but', 'CC')\n",
            "('the', 'DT')\n",
            "('frontal', 'JJ')\n",
            "('regions', 'NNS')\n",
            "('of', 'IN')\n",
            "('the', 'DT')\n",
            "('brain', 'NN')\n",
            "('attempting', 'VBG')\n",
            "('to', 'TO')\n",
            "('correct', 'VB')\n",
            "('an', 'DT')\n",
            "('inaccurate', 'JJ')\n",
            "('memory', 'NN')\n",
            "('.', '.')\n",
            "('Sheldon', 'NNP')\n",
            "('Cooper', 'NNP')\n",
            "('is', 'VBZ')\n",
            "('a', 'DT')\n",
            "('theoretical', 'JJ')\n",
            "('physicist', 'NN')\n",
            "('at', 'IN')\n",
            "('caltech', 'NN')\n",
            "('university', 'NN')\n",
            "('and', 'CC')\n",
            "('is', 'VBZ')\n",
            "('running', 'VBG')\n",
            "('up', 'RP')\n",
            "('for', 'IN')\n",
            "('nobel', 'JJ')\n",
            "('prize', 'NN')\n",
            "('for', 'IN')\n",
            "('his', 'PRP$')\n",
            "('theory', 'NN')\n",
            "('of', 'IN')\n",
            "('asymmetry', 'NN')\n",
            "('and', 'CC')\n",
            "('symmetry', 'NN')\n",
            "('in', 'IN')\n",
            "('universe', 'NN')\n",
            "('.', '.')\n",
            "('Sheldon', 'NNP')\n",
            "('does', 'VBZ')\n",
            "('not', 'RB')\n",
            "('think', 'VB')\n",
            "('that', 'IN')\n",
            "('dr.', 'JJ')\n",
            "('leonard', 'NN')\n",
            "('should', 'MD')\n",
            "('demand', 'VB')\n",
            "('to', 'TO')\n",
            "('be', 'VB')\n",
            "('in', 'IN')\n",
            "('charge', 'NN')\n",
            "('of', 'IN')\n",
            "('a', 'DT')\n",
            "('plasma', 'NN')\n",
            "('project', 'NN')\n",
            "('.', '.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "for word in stop_words:\n",
        "  print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjwY_Zkj610Z",
        "outputId": "7d83582e-7dda-4379-8705-2271cea13e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hasn\n",
            "both\n",
            "d\n",
            "own\n",
            "those\n",
            "did\n",
            "down\n",
            "it's\n",
            "nor\n",
            "them\n",
            "which\n",
            "wouldn't\n",
            "ma\n",
            "after\n",
            "shan\n",
            "o\n",
            "in\n",
            "what\n",
            "shouldn\n",
            "won't\n",
            "ours\n",
            "she's\n",
            "themselves\n",
            "couldn\n",
            "more\n",
            "for\n",
            "shan't\n",
            "these\n",
            "haven\n",
            "will\n",
            "the\n",
            "herself\n",
            "with\n",
            "are\n",
            "yourself\n",
            "its\n",
            "couldn't\n",
            "here\n",
            "yourselves\n",
            "isn't\n",
            "than\n",
            "a\n",
            "theirs\n",
            "wasn't\n",
            "won\n",
            "s\n",
            "hers\n",
            "i\n",
            "an\n",
            "hadn\n",
            "mightn't\n",
            "mightn\n",
            "don't\n",
            "aren\n",
            "myself\n",
            "other\n",
            "hasn't\n",
            "aren't\n",
            "weren't\n",
            "him\n",
            "itself\n",
            "haven't\n",
            "when\n",
            "whom\n",
            "until\n",
            "wouldn\n",
            "now\n",
            "m\n",
            "where\n",
            "you\n",
            "is\n",
            "isn\n",
            "this\n",
            "then\n",
            "should\n",
            "was\n",
            "you're\n",
            "doing\n",
            "it\n",
            "few\n",
            "ain\n",
            "were\n",
            "had\n",
            "y\n",
            "such\n",
            "because\n",
            "each\n",
            "ourselves\n",
            "mustn\n",
            "at\n",
            "has\n",
            "about\n",
            "me\n",
            "am\n",
            "our\n",
            "but\n",
            "or\n",
            "re\n",
            "above\n",
            "have\n",
            "same\n",
            "why\n",
            "my\n",
            "we\n",
            "before\n",
            "that'll\n",
            "been\n",
            "only\n",
            "doesn\n",
            "don\n",
            "all\n",
            "be\n",
            "any\n",
            "who\n",
            "you'll\n",
            "wasn\n",
            "needn\n",
            "hadn't\n",
            "shouldn't\n",
            "some\n",
            "that\n",
            "during\n",
            "between\n",
            "being\n",
            "his\n",
            "too\n",
            "so\n",
            "she\n",
            "if\n",
            "further\n",
            "as\n",
            "again\n",
            "you'd\n",
            "himself\n",
            "very\n",
            "mustn't\n",
            "from\n",
            "to\n",
            "out\n",
            "having\n",
            "does\n",
            "their\n",
            "they\n",
            "no\n",
            "ll\n",
            "on\n",
            "her\n",
            "most\n",
            "do\n",
            "while\n",
            "your\n",
            "yours\n",
            "against\n",
            "needn't\n",
            "of\n",
            "below\n",
            "weren\n",
            "should've\n",
            "ve\n",
            "there\n",
            "once\n",
            "didn\n",
            "just\n",
            "up\n",
            "t\n",
            "over\n",
            "off\n",
            "you've\n",
            "he\n",
            "how\n",
            "didn't\n",
            "under\n",
            "can\n",
            "through\n",
            "and\n",
            "into\n",
            "doesn't\n",
            "by\n",
            "not\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "for token in filtered_tokens:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0ZqZ37v7QTJ",
        "outputId": "75a5b4db-2843-425f-fbce-7a796ce4e435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caltech\n",
            "astrophysicist\n",
            "finds\n",
            "proof\n",
            "alien\n",
            "life\n",
            ".\n",
            "Amy\n",
            "neuroscientist\n",
            "know\n",
            "latest\n",
            "research\n",
            "deja-vu\n",
            "nothing\n",
            "frontal\n",
            "regions\n",
            "brain\n",
            "attempting\n",
            "correct\n",
            "inaccurate\n",
            "memory\n",
            ".\n",
            "Sheldon\n",
            "Cooper\n",
            "theoretical\n",
            "physicist\n",
            "caltech\n",
            "university\n",
            "running\n",
            "nobel\n",
            "prize\n",
            "theory\n",
            "asymmetry\n",
            "symmetry\n",
            "universe\n",
            ".\n",
            "Sheldon\n",
            "think\n",
            "dr.\n",
            "leonard\n",
            "demand\n",
            "charge\n",
            "plasma\n",
            "project\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer  = PorterStemmer()\n",
        "stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
        "for token in stemmed_tokens:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFyFmDBe7s9w",
        "outputId": "fed6c4f1-7ee5-446e-ed57-1be49e18ae2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "caltech\n",
            "astrophysicist\n",
            "find\n",
            "proof\n",
            "alien\n",
            "life\n",
            ".\n",
            "ami\n",
            "neuroscientist\n",
            "know\n",
            "latest\n",
            "research\n",
            "deja-vu\n",
            "noth\n",
            "frontal\n",
            "region\n",
            "brain\n",
            "attempt\n",
            "correct\n",
            "inaccur\n",
            "memori\n",
            ".\n",
            "sheldon\n",
            "cooper\n",
            "theoret\n",
            "physicist\n",
            "caltech\n",
            "univers\n",
            "run\n",
            "nobel\n",
            "prize\n",
            "theori\n",
            "asymmetri\n",
            "symmetri\n",
            "univers\n",
            ".\n",
            "sheldon\n",
            "think\n",
            "dr.\n",
            "leonard\n",
            "demand\n",
            "charg\n",
            "plasma\n",
            "project\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
        "for token in lemmatized_tokens:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFNTzTop8IwV",
        "outputId": "68245ac3-80ce-41ee-e63b-e1fb5a504e73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caltech\n",
            "astrophysicist\n",
            "find\n",
            "proof\n",
            "alien\n",
            "life\n",
            ".\n",
            "Amy\n",
            "neuroscientist\n",
            "know\n",
            "latest\n",
            "research\n",
            "deja-vu\n",
            "nothing\n",
            "frontal\n",
            "region\n",
            "brain\n",
            "attempting\n",
            "correct\n",
            "inaccurate\n",
            "memory\n",
            ".\n",
            "Sheldon\n",
            "Cooper\n",
            "theoretical\n",
            "physicist\n",
            "caltech\n",
            "university\n",
            "running\n",
            "nobel\n",
            "prize\n",
            "theory\n",
            "asymmetry\n",
            "symmetry\n",
            "universe\n",
            ".\n",
            "Sheldon\n",
            "think\n",
            "dr.\n",
            "leonard\n",
            "demand\n",
            "charge\n",
            "plasma\n",
            "project\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [document]\n",
        "tfid_vectorizer = TfidfVectorizer()\n",
        "tfid_matrix = tfid_vectorizer.fit_transform(corpus)\n",
        "print(tfid_matrix.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTRezBQj8jgH",
        "outputId": "a6755674-a5ac-40b8-a813-b859cec74a2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.09245003 0.09245003 0.09245003 0.2773501  0.09245003 0.09245003\n",
            "  0.09245003 0.09245003 0.09245003 0.09245003 0.09245003 0.09245003\n",
            "  0.18490007 0.09245003 0.09245003 0.09245003 0.09245003 0.09245003\n",
            "  0.09245003 0.09245003 0.09245003 0.18490007 0.09245003 0.09245003\n",
            "  0.18490007 0.09245003 0.09245003 0.2773501  0.09245003 0.09245003\n",
            "  0.09245003 0.09245003 0.09245003 0.09245003 0.09245003 0.09245003\n",
            "  0.09245003 0.36980013 0.09245003 0.09245003 0.09245003 0.09245003\n",
            "  0.09245003 0.09245003 0.09245003 0.09245003 0.18490007 0.09245003\n",
            "  0.09245003 0.09245003 0.2773501  0.09245003 0.09245003 0.09245003\n",
            "  0.18490007 0.09245003 0.09245003 0.09245003 0.09245003 0.18490007]]\n"
          ]
        }
      ]
    }
  ]
}